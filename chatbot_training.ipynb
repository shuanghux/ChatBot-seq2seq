{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np #matrix math \n",
    "import tensorflow as tf #machine learningt\n",
    "import helpers #for formatting data into batches and generating random sequence data\n",
    "from tensorflow.python.ops.rnn_cell import LSTMCell, LSTMStateTuple\n",
    "from tensorflow.python.layers.core import Dense\n",
    "from datasets.twitter import data\n",
    "import data_utils\n",
    "from tensorlayer.layers import *\n",
    "import tensorlayer as tl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class chatbot_seq2seq(object):\n",
    "    '''\n",
    "    chatbot implemented with seq2seq model.\n",
    "    Encoder: Bi-LSTM\n",
    "    Decoder: LSTM-Attention\n",
    "    '''\n",
    "    \n",
    "    #define init function for model\n",
    "    def __init__(self, vocab_size, input_embedding_size, encoder_hidden_units, decoder_hidden_units):\n",
    "        \n",
    "        '''Initialize Hparams'''\n",
    "        self.vocab_size = vocab_size\n",
    "        self.input_embedding_size = input_embedding_size\n",
    "        self.encoder_hidden_units = encoder_hidden_units\n",
    "        self.decoder_hidden_units = decoder_hidden_units\n",
    "        \n",
    "        \n",
    "        #Define placeholder\n",
    "        self.build_placeholder()\n",
    "        \n",
    "        #Define embedding matrix\n",
    "        self.build_emb_matrix()\n",
    "        \n",
    "        #Define Encoder as Bidirectional LSTM Cell\n",
    "        self.encoder_cell, self.encoder_final_state = self.build_encoder()\n",
    "        \n",
    "        #Define Decoder as Basic LSTM Cell\n",
    "        self.build_decoder()\n",
    "        \n",
    "        #Define Loss and Prediction\n",
    "        self.build_op()\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    def build_placeholder(self) :\n",
    "        '''Initialize Placeholders'''\n",
    "        #inputs dimension [encoder_max_time, batch_size]\n",
    "        self.encoder_inputs = tf.placeholder(shape=(None, None), dtype=tf.int32, name='encoder_inputs')\n",
    "        #retrieve_seq_length need argument with shape [batch_size, max_seq_len]\n",
    "        #encoder_inputs_length with shape [batch_size]\n",
    "        self.encoder_inputs_length = retrieve_seq_length_op2(tf.transpose(self.encoder_inputs))\n",
    "        #decoder_inputs with shape [max_seq_len, batch_size], in the form [start_id, how, are, you, pad_id...]\n",
    "        self.decoder_inputs = tf.placeholder(shape = (None, None), dtype = tf.int32, name = 'decoder_inputs')\n",
    "        #decoder targets with shape [max_seq_len, batch_size], in the form [how, are, you, end_id, pad_id ...]\n",
    "        self.decoder_targets = tf.placeholder(shape=(None, None), dtype=tf.int32, name='decoder_targets')\n",
    "        #target_masks [max_seq_len, batch_size]\n",
    "        self.decoder_masks = tf.placeholder(shape = (None, None), dtype = tf.int32, name = 'decoder_masks')\n",
    "        #go_tokens used for inference decode, with shape [batch_size]\n",
    "        self.go_tokens = tf.placeholder(shape = (None,), dtype = tf.int32, name = 'go_tokens')\n",
    "        #EOS token for inference, scalar\n",
    "        self.end_token = tf.placeholder(shape = (), dtype = tf.int32, name = 'end_token')\n",
    "        \n",
    "    def build_encoder(self):\n",
    "        encoder_cell = LSTMCell(self.encoder_hidden_units, initializer = tf.truncated_normal_initializer(stddev = 0.01))\n",
    "        self.encoder_cell = encoder_cell\n",
    "        ((encoder_fw_outputs,\n",
    "          encoder_bw_outputs),\n",
    "         (encoder_fw_final_state,\n",
    "          encoder_bw_final_state)) = (\n",
    "            tf.nn.bidirectional_dynamic_rnn(\n",
    "                cell_fw=encoder_cell,\n",
    "                cell_bw=encoder_cell,\n",
    "                inputs=self.encoder_inputs_embedded,\n",
    "                sequence_length=self.encoder_inputs_length,\n",
    "                dtype=tf.float32, time_major=True)\n",
    "            )\n",
    "        self.outputs, self.outputs_states = tf.nn.bidirectional_dynamic_rnn(\n",
    "                cell_fw=encoder_cell,\n",
    "                cell_bw=encoder_cell,\n",
    "                inputs=self.encoder_inputs_embedded,\n",
    "                sequence_length=self.encoder_inputs_length,\n",
    "                dtype=tf.float32, time_major=True)\n",
    "\n",
    "        #Concatenates tensors along one dimension.\n",
    "        self.encoder_outputs = tf.concat((encoder_fw_outputs, encoder_bw_outputs), 2)\n",
    "\n",
    "        #letters h and c are commonly used to denote \"output value\" and \"cell state\". \n",
    "        #http://colah.github.io/posts/2015-08-Understanding-LSTMs/ \n",
    "        #Those tensors represent combined internal state of the cell, and should be passed together. \n",
    "\n",
    "        encoder_final_state_c = tf.concat(\n",
    "            (encoder_fw_final_state.c, encoder_bw_final_state.c), 1)\n",
    "\n",
    "        encoder_final_state_h = tf.concat(\n",
    "            (encoder_fw_final_state.h, encoder_bw_final_state.h), 1)\n",
    "\n",
    "        #TF Tuple used by LSTM Cells for state_size, zero_state, and output state.\n",
    "        self.encoder_final_state = LSTMStateTuple(\n",
    "            c=encoder_final_state_c,\n",
    "            h=encoder_final_state_h\n",
    "        )\n",
    "        \n",
    "        return self.encoder_cell, self.encoder_final_state\n",
    "    \n",
    "    def build_emb_matrix(self) :\n",
    "        '''Initialize Embedding Matrix'''\n",
    "        #this operation is moved to CPU as some bugs in emb_lookup's GPU implementation\n",
    "        with tf.device(\"/cpu:0\"):\n",
    "            #randomly initialized embedding matrrix that can fit input sequence\n",
    "            #used to convert sequences to vectors (embeddings) for both encoder and decoder of the right size\n",
    "            #reshaping is a thing, in TF you gotta make sure you tensors are the right shape (num dimensions)\n",
    "            self.embeddings = tf.Variable(tf.random_uniform([self.vocab_size, self.input_embedding_size], -0.1, 0.1), dtype=tf.float32)\n",
    "            self.encoder_inputs_embedded = tf.nn.embedding_lookup(self.embeddings, self.encoder_inputs)\n",
    "            self.decoder_inputs_embedded = tf.nn.embedding_lookup(self.embeddings, self.decoder_inputs)\n",
    "            \n",
    "    \n",
    "    def build_decoder(self) :\n",
    "        '''Define Decoder as Basic LSTM Cell'''\n",
    "        self.decoder_cell = LSTMCell(self.decoder_hidden_units, initializer = tf.truncated_normal_initializer(stddev = 0.01))\n",
    "        \n",
    "        self.encoder_max_time, self.batch_size = tf.unstack(tf.shape(self.encoder_inputs))\n",
    "        #????????????\n",
    "        self.decoder_lengths = self.encoder_inputs_length * 0 + tf.reduce_max(retrieve_seq_length_op2(tf.transpose(self.decoder_masks)))\n",
    "        # +2 additional steps, +1 leading <EOS> token for decoder inputs\n",
    "        self.projection_layer = Dense(units = self.vocab_size, use_bias = True)\n",
    "        #Training Helper\n",
    "        self.train_helper = tf.contrib.seq2seq.TrainingHelper(\n",
    "            self.decoder_inputs_embedded, self.decoder_lengths, time_major = True)\n",
    "        #Training Decoder\n",
    "        self.train_decoder = tf.contrib.seq2seq.BasicDecoder(\n",
    "                self.decoder_cell, self.train_helper, self.encoder_final_state, output_layer = self.projection_layer)\n",
    "        #Training Output\n",
    "        self.train_decoder_outputs, _, _ = tf.contrib.seq2seq.dynamic_decode(decoder = self.train_decoder,output_time_major = True, maximum_iterations= 26)\n",
    "        #Inferencing Helper\n",
    "        self.infer_helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(\n",
    "            self.embeddings, start_tokens = self.go_tokens, end_token = self.end_token)\n",
    "         #Training Decoder\n",
    "        self.infer_decoder = tf.contrib.seq2seq.BasicDecoder(\n",
    "                self.decoder_cell, self.infer_helper, self.encoder_final_state, output_layer = self.projection_layer)\n",
    "        #Training Output\n",
    "        self.infer_decoder_outputs, _, _ = tf.contrib.seq2seq.dynamic_decode(decoder = self.infer_decoder,output_time_major = True, maximum_iterations= 25)\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        #Beam Search\n",
    "        self.beam_encoder_state = tf.contrib.seq2seq.tile_batch(\n",
    "            self.encoder_final_state, multiplier = 5)\n",
    "        self.beam_decoder = tf.contrib.seq2seq.BeamSearchDecoder(\n",
    "            cell = self.decoder_cell,\n",
    "            embedding = self.embeddings,\n",
    "            start_tokens = self.go_tokens,\n",
    "            end_token = self.end_token,\n",
    "            initial_state = self.beam_encoder_state,\n",
    "            beam_width = 5,\n",
    "            output_layer = self.projection_layer)\n",
    "        self.beam_outputs, _, _ = tf.contrib.seq2seq.dynamic_decode(decoder = self.beam_decoder,output_time_major = True, maximum_iterations= 25)\n",
    "    def build_op(self) :\n",
    "        self.train_logits = self.train_decoder_outputs.rnn_output\n",
    "        self.decoder_prediction = tf.argmax(self.infer_decoder_outputs.rnn_output, 2)\n",
    "        #cross_entropy with shape [max_seq_len, batch_size]\n",
    "        self.cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(\n",
    "                labels=tf.one_hot(self.decoder_targets, depth=self.vocab_size, dtype=tf.float32),\n",
    "                logits = self.train_logits)\n",
    "\n",
    "        #loss function\n",
    "        self.loss = tf.reduce_sum(self.cross_entropy * tf.cast(self.decoder_masks, tf.float32))\n",
    "        #train it \n",
    "        self.train_op = tf.train.AdamOptimizer().minimize(self.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = chatbot_seq2seq(\n",
    "    vocab_size = xvocab_size, \n",
    "    input_embedding_size = emb_dim, \n",
    "    encoder_hidden_units = emb_dim, \n",
    "    decoder_hidden_units = 2 * emb_dim\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMStateTuple(c=<tf.Tensor 'concat_1:0' shape=(?, 2048) dtype=float32>, h=<tf.Tensor 'concat_2:0' shape=(?, 2048) dtype=float32>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.encoder_final_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.attn_mechanism = tf.contrib.seq2seq.BahdanauAttention(\n",
    "    num_units = model.decoder_hidden_units, \n",
    "    memory = model.encoder_outputs,\n",
    "    memory_sequence_length = model.encoder_inputs_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.attn_decoder_cell = tf.contrib.seq2seq.AttentionWrapper(\n",
    "    cell = model.decoder_cell,\n",
    "    attention_mechanism = model.attn_mechanism,\n",
    "    attention_layer_size = model.decoder_hidden_units,\n",
    "    name = 'attn_decoder_cell')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'concat_1:0' shape=(?, 2048) dtype=float32>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.encoder_final_state[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_prefix = 'test_ckpt_dir'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from pickle and npy files\n",
    "metadata, idx_q, idx_a = data.load_data(PATH='datasets/twitter/')\n",
    "(trainX, trainY), (testX, testY), (validX, validY) = data_utils.split_dataset(idx_q, idx_a)\n",
    "\n",
    "# pre-process training data part I\n",
    "trainX = trainX.tolist()\n",
    "trainY = trainY.tolist()\n",
    "trainX = tl.prepro.remove_pad_sequences(trainX)\n",
    "trainY = tl.prepro.remove_pad_sequences(trainY)\n",
    "\n",
    "# parameters \n",
    "xseq_len = len(trainX)\n",
    "yseq_len = len(trainY)\n",
    "assert xseq_len == yseq_len\n",
    "BATCH_SIZE = 32\n",
    "xvocab_size = len(metadata['idx2w'])  \n",
    "yvocab_size = xvocab_size\n",
    "emb_dim = 1024\n",
    "\n",
    "encoder_max_time = 20\n",
    "decoder_max_time = encoder_max_time\n",
    "\n",
    "# updata parameters with preprocessing\n",
    "w2idx = metadata['w2idx']\n",
    "idx2w = metadata['idx2w']\n",
    "unk_id = w2idx['unk']\n",
    "pad_id = w2idx['_']\n",
    "start_id = xvocab_size\n",
    "end_id = xvocab_size+1\n",
    "w2idx.update({'start_id': start_id})\n",
    "w2idx.update({'end_id': end_id})\n",
    "idx2w = idx2w + ['start_id', 'end_id']\n",
    "xvocab_size = yvocab_size = xvocab_size + 2\n",
    "\n",
    "# A data for Seq2Seq should look like this:\n",
    "# input_seqs : ['how', 'are', 'you', '<PAD_ID'>]\n",
    "# decode_seqs : ['<START_ID>', 'I', 'am', 'fine', '<PAD_ID'>]\n",
    "# target_seqs : ['I', 'am', 'fine', '<END_ID>', '<PAD_ID'>]\n",
    "# target_mask : [1, 1, 1, 1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8004"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xvocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot_train_next_batch(model, iterator, go_id, end_id):\n",
    "    X, Y = iterator.__next__()\n",
    "    #[batch_size, max_seq_len]\n",
    "    _encoder_seqs = tl.prepro.pad_sequences(X)\n",
    "    _target_seqs = tl.prepro.sequences_add_end_id(Y, end_id = end_id)\n",
    "    ##[batch_size, max_seq_len]\n",
    "    _target_seqs = tl.prepro.pad_sequences(_target_seqs)\n",
    "    _decode_seqs = tl.prepro.sequences_add_start_id(Y, start_id = start_id, remove_last = False)\n",
    "    #[batch_size, max_seq_len]\n",
    "    _decode_seqs = tl.prepro.pad_sequences(_decode_seqs)\n",
    "    #[batch_size, max_seq_len]\n",
    "    _target_masks = tl.prepro.sequences_get_mask(_target_seqs)\n",
    "    return {\n",
    "        model.encoder_inputs: np.array(_encoder_seqs).T,\n",
    "        model.decoder_inputs: np.array(_decode_seqs).T,\n",
    "        model.decoder_targets: np.array(_target_seqs).T,\n",
    "        model.decoder_masks: _target_masks.T,\n",
    "        model.go_tokens: np.zeros(len(_encoder_seqs)) + go_id,\n",
    "        model.end_token: end_id\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = tl.iterate.minibatches(inputs = trainX, targets = trainY, batch_size = BATCH_SIZE, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd = iterator.__next__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd = chatbot_train_next_batch(model, iterator, start_id, end_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8002,   37,    2,  409, 1715,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd[model.decoder_inputs][:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True,device_count={'GPU':1}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized\n"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "if tf.train.checkpoint_exists(checkpoint_prefix) :\n",
    "    saver.restore(sess, tf.train.latest_checkpoint(checkpoint_prefix))\n",
    "    print('Restoring model parameters successful')\n",
    "else :\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print('Model initialized')\n",
    "# Training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 2863/2863 -- loss: 1083.6490478516 -- Speed: 5.359 batches/second"
     ]
    }
   ],
   "source": [
    "num_epoch = 2\n",
    "\n",
    "batchs_per_epoch = int(len(trainX) / BATCH_SIZE)\n",
    "for i in range(num_epoch):\n",
    "    iterator = tl.iterate.minibatches(inputs = trainX, targets = trainY, batch_size = BATCH_SIZE, shuffle = False)\n",
    "    time_start = time.time()\n",
    "    for j in range(batchs_per_epoch):\n",
    "        fd = chatbot_train_next_batch(model, iterator, start_id, end_id)\n",
    "        _, l = sess.run([model.train_op, model.loss], fd)\n",
    "        speed = (j+1)/(time.time() - time_start)\n",
    "        sys.stdout.write('\\rStep: %i/%i -- loss: %.10f -- Speed: %.3f batches/second' % (j+1, batchs_per_epoch, l, speed))\n",
    "        sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model training finished and saved!\n"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "save_path = saver.save(sess, '/model.ckpt')\n",
    "print(\"\\nModel training finished and saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = tl.iterate.minibatches(inputs = trainX, targets = trainY, batch_size = BATCH_SIZE, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd = chatbot_train_next_batch(model, iterator, start_id, end_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19, 32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd[model.encoder_inputs].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = iterator.__next__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[batch_size, max_seq_len]\n",
    "_encoder_seqs = tl.prepro.pad_sequences(X)\n",
    "_target_seqs = tl.prepro.sequences_add_end_id(Y, end_id = end_id)\n",
    "##[batch_size, max_seq_len]\n",
    "_target_seqs = tl.prepro.pad_sequences(_target_seqs)\n",
    "_decode_seqs = tl.prepro.sequences_add_start_id(Y, start_id = start_id, remove_last = False)\n",
    "#[batch_size, max_seq_len]\n",
    "_decode_seqs = tl.prepro.pad_sequences(_decode_seqs)\n",
    "#[batch_size, max_seq_len]\n",
    "_target_masks = tl.prepro.sequences_get_mask(_target_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19, 32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(_encoder_seqs).T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26, 32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(_target_seqs).T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
