{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np #matrix math \n",
    "import tensorflow as tf #machine learningt\n",
    "import helpers #for formatting data into batches and generating random sequence data\n",
    "from tensorflow.python.ops.rnn_cell import LSTMCell, LSTMStateTuple\n",
    "from tensorflow.python.layers.core import Dense\n",
    "from datasets.twitter import data\n",
    "import data_utils\n",
    "from tensorlayer.layers import *\n",
    "import tensorlayer as tl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# load data from pickle and npy files\n",
    "metadata, idx_q, idx_a = data.load_data(PATH='datasets/cornell_corpus/')\n",
    "(trainX, trainY), (testX, testY), (validX, validY) = data_utils.split_dataset(idx_q, idx_a)\n",
    "\n",
    "# pre-process training data part I\n",
    "trainX = trainX.tolist()\n",
    "trainY = trainY.tolist()\n",
    "trainX = tl.prepro.remove_pad_sequences(trainX)\n",
    "trainY = tl.prepro.remove_pad_sequences(trainY)\n",
    "\n",
    "# parameters \n",
    "xseq_len = len(trainX)\n",
    "yseq_len = len(trainY)\n",
    "assert xseq_len == yseq_len\n",
    "BATCH_SIZE = 32\n",
    "xvocab_size = len(metadata['idx2w'])  \n",
    "yvocab_size = xvocab_size\n",
    "emb_dim = 1024\n",
    "\n",
    "encoder_max_time = 20\n",
    "decoder_max_time = encoder_max_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8002"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xvocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" A data for Seq2Seq should look like this:\\ninput_seqs : ['how', 'are', 'you', '<PAD_ID'>]\\ndecode_seqs : ['<START_ID>', 'I', 'am', 'fine', '<PAD_ID'>]\\ntarget_seqs : ['I', 'am', 'fine', '<END_ID>', '<PAD_ID'>]\\ntarget_mask : [1, 1, 1, 1, 0]\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# updata parameters with preprocessing\n",
    "w2idx = metadata['w2idx']\n",
    "idx2w = metadata['idx2w']\n",
    "unk_id = w2idx['unk']\n",
    "pad_id = w2idx['_']\n",
    "start_id = xvocab_size\n",
    "end_id = xvocab_size+1\n",
    "w2idx.update({'start_id': start_id})\n",
    "w2idx.update({'end_id': end_id})\n",
    "idx2w = idx2w + ['start_id', 'end_id']\n",
    "xvocab_size = yvocab_size = xvocab_size + 2\n",
    "\n",
    "\"\"\" A data for Seq2Seq should look like this:\n",
    "input_seqs : ['how', 'are', 'you', '<PAD_ID'>]\n",
    "decode_seqs : ['<START_ID>', 'I', 'am', 'fine', '<PAD_ID'>]\n",
    "target_seqs : ['I', 'am', 'fine', '<END_ID>', '<PAD_ID'>]\n",
    "target_mask : [1, 1, 1, 1, 0]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = tl.iterate.minibatches(inputs = trainX, targets = trainY, batch_size = BATCH_SIZE, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32,)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd = chatbot_train_next_batch(start_id)\n",
    "fd[go_tokens].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(5/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot_train_next_batch(go_id):\n",
    "    X, Y = iterator.__next__()\n",
    "    #[batch_size, max_seq_len]\n",
    "    _encoder_seqs = tl.prepro.pad_sequences(X)\n",
    "    _target_seqs = tl.prepro.sequences_add_end_id(Y, end_id = end_id)\n",
    "    ##[batch_size, max_seq_len]\n",
    "    _target_seqs = tl.prepro.pad_sequences(_target_seqs)\n",
    "    _decode_seqs = tl.prepro.sequences_add_start_id(Y, start_id = start_id, remove_last = False)\n",
    "    #[batch_size, max_seq_len]\n",
    "    _decode_seqs = tl.prepro.pad_sequences(_decode_seqs)\n",
    "    #[batch_size, max_seq_len]\n",
    "    _target_masks = tl.prepro.sequences_get_mask(_target_seqs)\n",
    "    return {\n",
    "        encoder_inputs: np.array(_encoder_seqs).T,\n",
    "        decoder_targets: np.array(_target_seqs).T,\n",
    "        decoder_masks: _target_masks.T,\n",
    "        go_tokens: np.zeros(len(_encoder_seqs)) + go_id\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8004"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xvocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "vocab_size = xvocab_size\n",
    "input_embedding_size = emb_dim #character length\n",
    "\n",
    "encoder_hidden_units = emb_dim #num neurons\n",
    "decoder_hidden_units = encoder_hidden_units * 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `encoder_inputs` int32 tensor is shaped `[encoder_max_time, batch_size]`\n",
    "- `decoder_targets` int32 tensor is shaped `[decoder_max_time, batch_size]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputs dimension [encoder_max_time, batch_size]\n",
    "encoder_inputs = tf.placeholder(shape=(None, None), dtype=tf.int32, name='encoder_inputs')\n",
    "#contains the lengths for each of the sequence in the batch, we will pad so all the same\n",
    "#if you don't want to pad, check out dynamic memory networks to input variable length sequences\n",
    "#retrieve_seq_length need argument with shape [batch_size, max_seq_len]\n",
    "encoder_inputs_length = retrieve_seq_length_op2(tf.transpose(encoder_inputs))\n",
    "decoder_targets = tf.placeholder(shape=(None, None), dtype=tf.int32, name='decoder_targets')\n",
    "#target_masks [max_seq_len, batch_size]\n",
    "decoder_masks = tf.placeholder(shape = (None, None), dtype = tf.int32, name = 'decoder_masks')\n",
    "go_tokens = tf.placeholder(shape = (None,), dtype = tf.int32, name = 'go_tokens')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Embedding Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(\"/cpu:0\"):\n",
    "    #randomly initialized embedding matrrix that can fit input sequence\n",
    "    #used to convert sequences to vectors (embeddings) for both encoder and decoder of the right size\n",
    "    #reshaping is a thing, in TF you gotta make sure you tensors are the right shape (num dimensions)\n",
    "    embeddings = tf.Variable(tf.random_uniform([vocab_size, input_embedding_size], -1.0, 1.0), dtype=tf.float32)\n",
    "\n",
    "    #this thing could get huge in a real world application\n",
    "\n",
    "    encoder_inputs_embedded = tf.nn.embedding_lookup(embeddings, encoder_inputs)\n",
    "    decoder_inputs_embedded = tf.nn.embedding_lookup(embeddings, decoder_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess inputs and outputs\n",
    "- my_encoder_inputs: Dimension(8, batch_size)\n",
    "- my_encoder_inputs_length: Dimension(batch_size)\n",
    "- my_decoder_targets: Dimension(11, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "batches = helpers.random_sequences(length_from=3, length_to=8,\n",
    "                                   vocab_lower=2, vocab_upper=10,\n",
    "                                   batch_size=batch_size)\n",
    "def next_feed():\n",
    "    batch = next(batches)\n",
    "    encoder_inputs_, encoder_input_lengths_ = helpers.batch(batch)\n",
    "    decoder_targets_, _ = helpers.batch(\n",
    "        [(sequence) + [EOS] + [PAD] * 2 for sequence in batch]\n",
    "    )\n",
    "    return {\n",
    "        encoder_inputs: encoder_inputs_,\n",
    "        encoder_inputs_length: encoder_input_lengths_,\n",
    "        decoder_targets: decoder_targets_,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig = next_feed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_seq_len(batch_x):\n",
    "    #batch_x with shape [seq_len, batch_size]\n",
    "    return [np.nonzero(batch_x[:,i])[0].size for i in range(batch_x.shape[1])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Encoder as Bidirectional LSTM Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_cell = LSTMCell(encoder_hidden_units)\n",
    "\n",
    "((encoder_fw_outputs,\n",
    "  encoder_bw_outputs),\n",
    " (encoder_fw_final_state,\n",
    "  encoder_bw_final_state)) = (\n",
    "    tf.nn.bidirectional_dynamic_rnn(cell_fw=encoder_cell,\n",
    "                                    cell_bw=encoder_cell,\n",
    "                                    inputs=encoder_inputs_embedded,\n",
    "                                    sequence_length=encoder_inputs_length,\n",
    "                                    dtype=tf.float32, time_major=True)\n",
    "    )\n",
    "\n",
    "#Concatenates tensors along one dimension.\n",
    "encoder_outputs = tf.concat((encoder_fw_outputs, encoder_bw_outputs), 2)\n",
    "\n",
    "#letters h and c are commonly used to denote \"output value\" and \"cell state\". \n",
    "#http://colah.github.io/posts/2015-08-Understanding-LSTMs/ \n",
    "#Those tensors represent combined internal state of the cell, and should be passed together. \n",
    "\n",
    "encoder_final_state_c = tf.concat(\n",
    "    (encoder_fw_final_state.c, encoder_bw_final_state.c), 1)\n",
    "\n",
    "encoder_final_state_h = tf.concat(\n",
    "    (encoder_fw_final_state.h, encoder_bw_final_state.h), 1)\n",
    "\n",
    "#TF Tuple used by LSTM Cells for state_size, zero_state, and output state.\n",
    "encoder_final_state = LSTMStateTuple(\n",
    "    c=encoder_final_state_c,\n",
    "    h=encoder_final_state_h\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Decoder as Basic LSTM Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_cell = LSTMCell(decoder_hidden_units)\n",
    "encoder_max_time, batch_size = tf.unstack(tf.shape(encoder_inputs))\n",
    "#????????????\n",
    "decoder_lengths = encoder_inputs_length * 0 + tf.reduce_max(retrieve_seq_length_op2(tf.transpose(decoder_masks)))\n",
    "# +2 additional steps, +1 leading <EOS> token for decoder inputs\n",
    "projection_layer = Dense(units = vocab_size, use_bias = True)\n",
    "#Training Helper\n",
    "# helper = tf.contrib.seq2seq.TrainingHelper(\n",
    "#         decoder_inputs_embedded, decoder_lengths, time_major = True)\n",
    "#Inferencing Helper\n",
    "helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(embeddings, start_tokens = go_tokens, end_token = end_id)\n",
    "decoder = tf.contrib.seq2seq.BasicDecoder(\n",
    "        decoder_cell, helper, encoder_final_state, output_layer = projection_layer)\n",
    "decoder_outputs, _, _ = tf.contrib.seq2seq.dynamic_decode(decoder = decoder,output_time_major = True, maximum_iterations= 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss and Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = decoder_outputs.rnn_output\n",
    "decoder_prediction = tf.argmax(logits, 2)\n",
    "#cross_entropy with shape [max_seq_len, batch_size]\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(\n",
    "        labels=tf.one_hot(decoder_targets, depth=vocab_size, dtype=tf.float32),\n",
    "        logits = logits)\n",
    "\n",
    "#loss function\n",
    "loss = tf.reduce_mean(cross_entropy * tf.cast(decoder_masks, tf.float32))\n",
    "#train it \n",
    "train_op = tf.train.AdamOptimizer().minimize(loss)\n",
    "# train_op = tf.train.MomentumOptimizer(0.01,0.9).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py:1711: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sess = tf.InteractiveSession(config=tf.ConfigProto(allow_soft_placement=True,device_count={'GPU':1}))\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd = chatbot_train_next_batch(start_id)\n",
    "predict_ = sess.run(decoder_prediction, fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0\n",
      "  minibatch loss: 2.8437368869781494\n",
      "  sample 1:\n",
      "    input     > [   3   16  263   37   18    6 2483 7144   13  124   97   19   23  285\n",
      " 1884   24  259  226 2066]\n",
      "    predicted > [   3    3    3    3    3    9    9    4    4    1    9    1    1    5\n",
      "    4    5   11    3    3    3 8003    2    2 8003 8003]\n",
      "  sample 2:\n",
      "    input     > [  32   31   35    6 1554 1529    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0]\n",
      "    predicted > [  37    2    2    2 8003 8003 8003 8003 8003 8003 8003 8003 8003  623\n",
      "  623  623  623 1289 1289 1289 1289 1289 1289 1289 1289]\n",
      "  sample 3:\n",
      "    input     > [ 61   3  16  88 102  31   6 483 419   0   0   0   0   0   0   0   0   0\n",
      "   0]\n",
      "    predicted > [  87   13 8003 8003 8003 8003 8003 8003 8003 8003  623  623  623  623\n",
      "  623  623  623  623 1289 1289 1289 1289 1289 1289 1289]\n",
      "\n",
      "batch 1000\n",
      "  minibatch loss: 0.060268811881542206\n",
      "  sample 1:\n",
      "    input     > [120   2  52  76  12   8  75  82 124  13   9   1  22 260  85   1  44  58\n",
      "  17 279   0   0   0   0]\n",
      "    predicted > [   3   50   32   31  529    6 1070   29   81  200 6705 3475   11   63\n",
      "   10    4 3569 3581 4208 8003]\n",
      "  sample 2:\n",
      "    input     > [  2 550   5  21  81 473  19 227   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0]\n",
      "    predicted > [  97  203   34    9 8003    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0]\n",
      "  sample 3:\n",
      "    input     > [ 8 16  2 51  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "    predicted > [   4 7751 1097 8003    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0]\n",
      "\n",
      "batch 2000\n",
      "  minibatch loss: 0.005124016664922237\n",
      "  sample 1:\n",
      "    input     > [  43    2   20   79    5  938   12    4 1035   14    6 2500  703  187\n",
      "   46    2   51    5   71    5 2882    0    0    0    0]\n",
      "    predicted > [  43   30   58 8003    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0]\n",
      "  sample 2:\n",
      "    input     > [ 306   35   22   21   85 1076 4763   13   41  120   85  217   10    6\n",
      "    1    0    0    0    0    0    0    0    0    0    0]\n",
      "    predicted > [  42   14    9    8   40   17   14  259   21    6  317   34   91  603\n",
      "   41 8003    0    0    0    0    0    0]\n",
      "  sample 3:\n",
      "    input     > [  16    2   21  116  181 2024 1149    9   22   52   90   60    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    predicted > [  24  110   64  198    6  304 8003    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0]\n",
      "\n"
     ]
    },
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-9d4814660cae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mfd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchatbot_train_next_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mloss_track\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-ffbc5cc51baf>\u001b[0m in \u001b[0;36mchatbot_train_next_batch\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mchatbot_train_next_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;31m#[batch_size, max_seq_len]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0m_encoder_seqs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0m_target_seqs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequences_add_end_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mend_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "loss_track = []\n",
    "max_batches = 5001\n",
    "batches_in_epoch = 1000\n",
    "\n",
    "try:\n",
    "    for batch in range(max_batches):\n",
    "        fd = chatbot_train_next_batch()\n",
    "        _, l = sess.run([train_op, loss], fd)\n",
    "        loss_track.append(l)\n",
    "\n",
    "        if batch == 0 or batch % (batches_in_epoch) == 0:\n",
    "            print('batch {}'.format(batch))\n",
    "            print('  minibatch loss: {}'.format(sess.run(loss, fd)))\n",
    "            predict_ = sess.run(decoder_prediction, fd)\n",
    "            for i, (inp, pred) in enumerate(zip(fd[encoder_inputs].T, predict_.T)):\n",
    "                \n",
    "                print('  sample {}:'.format(i + 1))\n",
    "                print('    input     > {}'.format(inp))\n",
    "                print('    predicted > {}'.format(pred))\n",
    "                if i >= 2:\n",
    "                    break\n",
    "            print()\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print('training interrupted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  4, 503,  10,  25, 265,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd[encoder_inputs][:,15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_s = [decode(sequence=fd[encoder_inputs][:,i], lookup=idx2w, separator=' ') for i in range(32)]\n",
    "a_s = [decode(sequence=predict_[:,i], lookup=idx2w, separator=' ') for i in range(32)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(sequence, lookup, separator=''): # 0 used for padding, is ignored\n",
    "    res = ''\n",
    "    for i in range(len(sequence)):\n",
    "        if sequence[i] != 0 and sequence[i] != 6003:\n",
    "            res += lookup[sequence[i]]+' '\n",
    "        else:\n",
    "            return res\n",
    "    return res\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the to i '"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode(sequence=[2,3,4,6003,2,1], lookup=idx2w, separator=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------\n",
      "    Q > can we make this quick unk unk and andrew barrett are having an incredibly unk public break up on the unk again \n",
      "    A > global perspective sudden killing shoots jewelry massey massey neither neither cross yoda accomplished der dated li brilliant cathy cathy audience \n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "    Q > not the unk and unk and unk part please \n",
      "    A > craft stupidity pete dropping yep seventyfive drove child loved toast active cab nap known leak ginger officially peaceful aware digging \n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "    Q > youre asking me out thats so cute whats your name again \n",
      "    A > enemy obvious sunny sunny truth truth side thirtysix jammed elena ocean elsewhere frock ethics claudia mothers patient fright sticking phrase \n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "    Q > gosh if only we could find kat a boyfriend \n",
      "    A > production spite souls otho affect chaos cigars crude ignorance sarah sarah hash sarah millions millions october mans q repressed woman \n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "    Q > unk ma unk this is my head \n",
      "    A > freddie soldiers soldiers reason fort diplomat von saints not rain wore believe feelin zack enter new new belle 18 linda \n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "    Q > how is our little find the unk a date plan unk \n",
      "    A > rex marla leo rex stag feeling phoned madison tear wholl lamb officer back federal grateful grateful rain fortunately fortunately wise \n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "    Q > you got something on your mind \n",
      "    A > turner thomas hoax happily shirt samuel babe twentyone ridiculous ridiculous ridiculous rowan uiu suffered began disk unpredictable obsessed students obsessed \n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "    Q > you have my word as a gentleman \n",
      "    A > valentine journal journal porno porno new new shocked shocked shocked blake fiction fiction fraulein hash twist hash wall reservations everybody \n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "    Q > sure have \n",
      "    A > rest assignment sneak ropes tin bookstore tokyo tokyo ghosts overcome strangely capacity fuck teenagers foreign thigh thompson basic lanes machine \n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "    Q > so thats the kind of guy she likes pretty ones \n",
      "    A > happy hospital discount give legitimate legitimate ears chemicals places iim x stiff serial wed automatic dessert radios stubborn dead overcome \n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "    Q > you know unk \n",
      "    A > crystal lester qualified qualified look look customs customs confession j patio liquid passage kitten kitten apparently becky askin wes wes \n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "    Q > i looked for you back at the party but you always seemed to be occupied \n",
      "    A > marijuana themselves psych cap standard stashed antiques papers pigeons actual bye law cells cheers were bounty nickel bloom destination necessarily \n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "    Q > well no \n",
      "    A > plissken valentine itself mueller wants farther lionel bureau stand pritchett burning disturb yah line peggy swim terrance shoes adm undead \n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "    Q > do you listen to this crap \n",
      "    A > freddie caliber caliber witch wager engine adopted abandon abandon dickson grow todays surgery surgery paso hot kong austin czech by \n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "    Q > me this unk blonde unk im like boring myself \n",
      "    A > afraid engines jacob heller accounted murders vanished how messy schwartz mccall un designed 1000 excited sylvia argument answer locks players \n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "    Q > i figured youd get to the good stuff eventually \n",
      "    A > cellular inspector watches strip genetic strip gentleman gentleman bait bait weight weight mallory experiments gabe parasites heard wealth riot homer \n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "    Q > the real you \n",
      "    A > crystal assist rooney real guarantee knights knights easy crabtree toto mature modest month month geordi geordi banking lovely betray carpet \n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "    Q > she okay \n",
      "    A > handle shoots envy envy missed fa beard sweetie than lawn fighters assuming cloth cops crusher hells twisted psychic definition 21 \n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "    Q > they do to \n",
      "    A > understudy signing asleep stage misery reset quincy cool element herring acid freaking freaking nuke introduced sam less accounts compartment activate \n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "    Q > i have to be home in twenty minutes \n",
      "    A > realized halloran swimming keeper quietly cooperation wholl located cooperation deanna deanna insane insane luke york elevator loyalty she she she \n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "    Q > you think you re the only unk at the prom \n",
      "    A > immediately francis crystal buys safer peggy peggy schmidt bosses freeze hearts sap feelings feelings poison hans colony hans ward ward \n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "    Q > hey sweet cheeks \n",
      "    A > spite personally history considered residence residence residence residence residence residence residence residence residence residence residence residence residence residence residence residence \n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "    Q > listen i want to talk to you about the prom \n",
      "    A > leads upsetting jj deflector treves goodnight donna reminded counsel song realistic realistic realistic realistic fucks looked learn drivin trusting supper \n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "    Q > whereve you been \n",
      "    A > jacques girlfriend merlin kick luc strings satisfaction bear eye germans usual absurd took extension extension girlfriend right right opening sit \n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "    Q > i have the potential to smack the crap out of you if you dont get out of my way \n",
      "    A > written annual distance detective well thatll well pier uhuh murray cabinet cabinet cabinet cabinet eighty eighty undead plate loved cab \n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "    Q > oh my god does this mean youre becoming normal \n",
      "    A > body wished whereas mature whereas disturb sources bureau outfit obrien obrien obrien examining lucky ages swing tide captured alley units \n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "    Q > youre ruining my life because you wont be normal i cant be normal \n",
      "    A > loretta humble talkin touched nono handles boy sometime a causing moving packs scientist actions interests wacko packs mommys role episode \n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "    Q > like im supposed to know what that even means \n",
      "    A > minnesota stop freddie unpredictable guarantee crowded ten investigation deputies glades limousine hafta robbed bracelet march crawford looked issues employed media \n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "    Q > you are so completely unk \n",
      "    A > senior shown lingerie es foolish foolish discovery discovery unable unable subway drowned vacuum 32 32 evan message listed quarter preysing \n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "    Q > bianca i need to talk to you i need to tell you \n",
      "    A > howd cap karras unh 40 almost floors floors pigs owed millions millions prey gibson been pursue army ted protect hands \n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "    Q > i dont get you you act like youre too good for any of this and then you go totally unk when you get here \n",
      "    A > halloran halloran quest quest quest disagree disagree mile willow weighs watches glimpse id courtroom theyre theyre modest gunshot health hooker \n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "    Q > listen i know you hate having to sit home because im not susie high school \n",
      "    A > conspiracy swinging motherfucker buti conduct quiet carlotta metro rug rug hostages rug removed affairs named affairs bloke bloke bloke k \n",
      "--------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(32):\n",
    "    print('--------------------------------------------------------------')\n",
    "    print('    Q > {}'.format(q_s[i]))\n",
    "    print('    A > {}'.format(a_s[i]))\n",
    "    print('--------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.0001 after Tensor(\"mul_2:0\", shape=(), dtype=int32) examples (batch_size=Tensor(\"unstack:1\", shape=(), dtype=int32))\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(loss_track)\n",
    "print('loss {:.4f} after {} examples (batch_size={})'.format(loss_track[-1], len(loss_track)*batch_size, batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorlayer.layers import *\n",
    "import tensorlayer as tl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2idx = metadata['w2idx']\n",
    "idx2w = metadata['idx2w']\n",
    "unk_id = w2idx['unk']\n",
    "pad_id = w2idx['_']\n",
    "start_id = xvocab_size\n",
    "end_id = xvocab_size+1\n",
    "w2idx.update({'start_id': start_id})\n",
    "w2idx.update({'end_id': end_id})\n",
    "idx2w = idx2w + ['start_id', 'end_id']\n",
    "xvocab_size = yvocab_size = xvocab_size + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = trainX.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = tl.prepro.remove_pad_sequences(trainX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "187262"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(187262, 20)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dad', 's', 'dad', 'is', 'our', 'new', 'favorite', 'person']\n"
     ]
    }
   ],
   "source": [
    "print([idx2w[id] for id in trainX[10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainY = trainY.tolist()\n",
    "trainY = tl.prepro.remove_pad_sequences(trainY)\n",
    "target_seqs = tl.prepro.sequences_add_end_id([trainY[10]], end_id)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[78, 342, 63, 68, 746, 6003]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['u', 'gotta', 'love', 'his', 'dad', 'end_id']\n"
     ]
    }
   ],
   "source": [
    "print([idx2w[id] for id in target_seqs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "decode_seqs = tl.prepro.sequences_add_start_id([trainY[10]], start_id = start_id, remove_last = False)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6002, 78, 342, 63, 68, 746]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['start_id', 'u', 'gotta', 'love', 'his', 'dad']\n"
     ]
    }
   ],
   "source": [
    "print([idx2w[id] for id in decode_seqs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_mask = tl.prepro.sequences_get_mask([target_seqs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_mask[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "feeder = chatbot_train_next_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = trainX[0:16], trainY[0:16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tl.prepro.pad_sequences(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "_target_seqs = tl.prepro.sequences_add_end_id(Y, end_id = end_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "_target_seqs = tl.prepro.pad_sequences(_target_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "_target_mask = tl.prepro.sequences_get_mask(_target_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 20)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_target_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "_decode_seqs = tl.prepro.sequences_add_start_id(Y, start_id = start_id, remove_last = False)\n",
    "_decode_seqs = tl.prepro.pad_sequences(_decode_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
